# GomokuAI
## 1. 개요

    2023년 2월 강화학습 스터디 프로젝트입니다.
    오목 게임을 통해 강화학습을 구현합니다.
    
    오목 게임은 15x15의 보드에서 5개의 돌을 먼저 놓은 사람이 승리하는 게임입니다.
    
    여러 강화학습 알고리즘들을 구현하고, 각 알고리즘들의 성능을 비교합니다.
    사람과도 플레이 할 수 있도록 합니다.

### 목차는 다음과 같습니다.
#


    1. 강화학습 알고리즘
        1) DQN
        추후 추가 예정

    2. 사람과의 대결
        1) 사람이 먼저 놓는 경우
        2) 사람이 나중에 놓는 경우

    3. 각 알고리즘의 성능 비교
        1) 각 알고리즘들의 승률 비교
        2) 각 알고리즘들의 플레이 시간 비교
        3) 각 알고리즘들의 플레이 횟수 비교

    4. 각 알고리즘의 성능 개선
        1) 각 알고리즘들의 성능 개선 방법
        2) 각 알고리즘들의 성능 개선 결과
##

## 2. 구현
### Env는 다음과 같이 구성됩니다.
##
    1) 보드
        보드는 15x15의 2차원 np.array로 구성됩니다.
        보드의 각 원소는 0, 1, -1로 구성되며, 0은 비어있음을 의미하고, 1은 흑돌, -1은 백돌을 의미합니다.
        step()을 받게 되면 자동으로 다음 돌로 변경하여 보드를 업데이트 합니다.
##
    2) Reward
        Reward는 이겼을 때의 경우, 승리에 근접한 경우, 패배한 경우, 패배에 근접한 경우, 그 외의 경우로 나누어 구현합니다.
        이겼을 때의 경우, 승리에 근접한 경우, 패배한 경우, 패배에 근접한 경우는 각각 1, 0.5, -1, -0.5의 reward를 받습니다.
        
        해당 경우들의 여부는 다음과 같이 판단합니다.
        1) 이겼을 때의 경우
            현재 보드에서 돌이 5개 이상 연속으로 놓여있는 경우
        
        2) 승리에 근접한 경우
            1. 현재 보드에서 돌이 반 닫힌 상태로 4개 이상 연속으로 놓여있는 경우,
            2. 현재 보드에서 돌이 모두 열린 상태로 3개 연속으로 놓여있는 경우,
            3. 닫힘 여부와 상관 없이 3-3이 완성되는 경우

        3) 패배한 경우
            현재 보드에서 상대방의 돌이 5개 이상 연속으로 놓여있는 경우

        4) 패배에 근접한 경우
            2) 승리에 근접한 경우가 상대방에게 적용된 경우
##
    3) Done
        Done은 다음과 같이 판단합니다.
        1) 현재 보드에서 돌이 5개 이상 연속으로 놓여있는 경우
        2) 현재 보드에서 돌이 225개가 놓여있는 경우
##
    4) Action
        Action은 다음과 같이 구현합니다.
        1) Action은 0~224의 정수로 구성됩니다.
        2) Action은 15x15의 2차원 np.array로 구성됩니다.
        3) Action은 (x, y)의 형태로 구성됩니다.
##
    5) Info
        Info는 다음과 같이 구현합니다.
        1) Info는 현재 보드의 상태를 나타내는 15x15의 2차원 np.array로 구성됩니다.
        2) Info는 0, 1, -1로 구성되며, 0은 비어있음을 의미하고, 1은 흑돌, -1은 백돌을 의미합니다.
##
    6) Reset
        Reset은 다음과 같이 구현합니다.
        1) Reset은 현재 보드의 상태를 초기화합니다.
        2) Reset은 현재 보드의 상태를 반환합니다.
##
    보드 구현은 pygame 라이브러리를 사용합니다.
##













